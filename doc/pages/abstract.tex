\chapter{\abstractname}

In 2008 the Institute of Neuroinformatics at UZH/ETHZ released a frame-free,
neuromorphic vision sensor. Its output is a continuous-time time series of
events that signify a local intensity change at one of its 128x128 pixels. In
this thesis, we utilize recurrent neural networks to perform gesture recognition
on such time series. Our main contribution is the use of an autoencoder network
for sequence compression which improves the performance of downstream
recognition systems significantly. We create a segmented, neuromorphic vision
dataset and demonstrate a recognition accuracy of 85\% on a validation set with
a hybrid system of recurrent neural networks and hidden Markov models. In
particular, we compare three different transformations of the event stream: the
raw event data, visual features extracted with a pre-trained neural network from
frame reconstructions and learned representations from an autoencoder.
Furthermore, we compare two methods for training neural network classifiers,
framewise classification and connectionist temporal classification, and two
methods for decoding classifications into a label sequence, HMM decoding and a
two-step process with HMM segmentation.
